---
title: "Make Your Own Model"
author: "Kenneth Arnold"
date: "`r Sys.Date()`"
output: 
  learnr::tutorial:
    progressive: false
    allow_skip: true
    toc: false
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
options(dplyr.summarise.inform = FALSE)
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE, eval=TRUE)
```

# Small data

We'll start by using a tiny subset of the home sale dataset.

```{r subset-data, echo=TRUE, eval=TRUE}
ames <- AmesHousing::make_ames()
data1 <- ames %>% slice_head(n = 2) %>% select(Lot_Area, Sale_Price)
```

## Intercept only

Adjust the value of "intercept" to make your line give the best prediction.

```{r plot-one-coef, exercise=TRUE, exercise.setup="subset-data"}
intercept <- 125000

ggplot(data1, aes(x = Lot_Area, y = Sale_Price)) +
  geom_point() +
  geom_abline(intercept = intercept, slope = 0)
```

Now, adjust both "intercept" and "coef_lot_area".

```{r plot_two_coef, exercise=TRUE, exercise.setup="subset-data"}
intercept = 125000
coef_lot_area <- .1

ggplot(data1, aes(x = Lot_Area, y = Sale_Price)) +
  geom_point() +
  geom_abline(intercept = intercept, slope = coef_lot_area)
```


# More data!

```{r subset-data-2, exercise.setup="subset-data"}
data2 <- ames %>% slice_head(n = 3)
```

```{r plot_two_coef_data2, exercise=TRUE, exercise.setup="subset-data-2"}
intercept = 125000
coef_lot_area <- .1

ggplot(data2, aes(x = Lot_Area, y = Sale_Price)) +
  geom_point() +
  geom_abline(intercept = intercept, slope = coef_lot_area)
```

# Evaluate error

Write code here to add a `prediction` and `residual` column to `data2`.
Make sure that you use the correct sign for *residual*.

```{r add-prediction, exercise=TRUE, exercise.setup="subset-data-2"}
intercept = 125000
coef_lot_area <- .1

data2_augmented <- data2 # Your code here
```

```{r add-prediction-solution, exercise.setup="subset-data-2"}
intercept = 125000
coef_lot_area <- .1

data2_augmented <- data2 %>%
  mutate(predicted = intercept + coef_lot_area * Lot_Area,
         residual = Sale_Price - predicted)
```

Now, write code that uses `data2_augmented` to compute the
*mean error* (bias), *mean absolute error*, and *mean squared error*. Use `summarize`.

```{r summarize-error, exercise=TRUE, exercise.setup="add-prediction-solution"}
data2_augmented %>% 
  summarize(
    mean_error = 0, # your code here
    mean_absolute_error = 0, # etc.
    mean_squared_error = 0
  )
```

```{r summarize-error-solution}
data2_augmented %>% 
  summarize(
    mean_error = mean(residual),
    mean_absolute_error = mean(abs(residual)),
    mean_squared_error = mean(residual * residual)
  )
```

